{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import iglob\n",
    "from time import time\n",
    "\n",
    "from skimage.io import imread, imsave, show, imshow\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обрезаем изображения в базе\n",
    "koef = 0.3\n",
    "new_size = (50, 50)\n",
    "input_dirs_path = ['02', '07']\n",
    "for input_dir_path in input_dirs_path:\n",
    "    output_dir_path = input_dir_path + '_output'\n",
    "    for filename in iglob(input_dir_path + '/*.jpeg'):\n",
    "        img = imread(filename)\n",
    "        img = resize(img, new_size) * 255\n",
    "        img = img[1:-1, 1:-1]\n",
    "        img = img.astype('uint8')\n",
    "        thresh = threshold_otsu(img)\n",
    "        bin = img < thresh\n",
    "        nr, nc = new_size\n",
    "        cat_bin = bin[:, : int(nc * koef)]\n",
    "        cat_top = cat_bin.sum(axis = 1).nonzero()[0][0]\n",
    "        cat_bin = cat_bin[cat_top :, :]\n",
    "        cat_bot = cat_bin.sum(axis = 1).argmin()\n",
    "        cat_bin = cat_bin[: cat_bot, :]\n",
    "        img = img[cat_top : cat_bot, :]\n",
    "        imsave(output_dir_path + '/' + filename[len(input_dir_path) + 1:], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Горизонтальные линии\n",
    "def get_val(img):\n",
    "    thresh = threshold_otsu(img)\n",
    "    bin = img < thresh\n",
    "    skl = skeletonize(bin)\n",
    "    lbl = label(skl)\n",
    "    cnt_lbl = np.bincount(lbl.reshape(-1))\n",
    "    max_lbl = np.argmax(cnt_lbl[1:]) + 1\n",
    "    lbl[lbl != max_lbl] = 0\n",
    "    lbl[lbl == max_lbl] = 1\n",
    "    pxl = lbl.sum()\n",
    "    r, c = lbl.shape\n",
    "    dist = lbl[np.arange(r - 1, -1, -1), :].argmax(axis = 0)\n",
    "    hist = list(np.histogram(dist, bins=np.arange(dist.max() + 1)))\n",
    "    hist[0] -= hist[0].min()\n",
    "    return np.array(hist[0]).nonzero()[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Горизонтальные линии с resize'ом\n",
    "def get_val(img):\n",
    "    new_size = (18, 50)\n",
    "    thresh = threshold_otsu(img)\n",
    "    bin = img < thresh\n",
    "    bin = resize(bin, new_size)\n",
    "    bin = bin[1:-1, 1:-1] * 255\n",
    "    bin = bin.astype('uint8')\n",
    "    thresh = threshold_otsu(bin)\n",
    "    bin = bin > thresh\n",
    "    skl = skeletonize(bin)\n",
    "    lbl = label(skl)\n",
    "    cnt_lbl = np.bincount(lbl.reshape(-1))\n",
    "    max_lbl = np.argmax(cnt_lbl[1:]) + 1\n",
    "    lbl[lbl != max_lbl] = 0\n",
    "    lbl[lbl == max_lbl] = 1\n",
    "    pxl = lbl.sum()\n",
    "    r, c = lbl.shape\n",
    "    dist = lbl[np.arange(r - 1, -1, -1), :].argmax(axis = 0)\n",
    "    hist = list(np.histogram(dist, bins=np.arange(dist.max() + 1)))\n",
    "    hist[0] -= hist[0].min()\n",
    "    return np.array(hist[0]).nonzero()[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Гистограмма расстояний от нижнего края\n",
    "def get_val(img):\n",
    "    thresh = threshold_otsu(img)\n",
    "    bin = img < thresh\n",
    "    skl = skeletonize(bin)\n",
    "    lbl = label(skl)\n",
    "    cnt_lbl = np.bincount(lbl.reshape(-1))\n",
    "    max_lbl = np.argmax(cnt_lbl[1:]) + 1\n",
    "    lbl[lbl != max_lbl] = 0\n",
    "    lbl[lbl == max_lbl] = 1\n",
    "    pxl = lbl.sum()\n",
    "    r, c = lbl.shape\n",
    "    dist = lbl[np.arange(r - 1, -1, -1), :].argmax(axis = 0)\n",
    "    hist = list(np.histogram(dist, bins=np.arange(dist.max() + 1)))\n",
    "    hist[0] -= hist[0].min()\n",
    "    return hist[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ориентация скелета\n",
    "def get_val(img):\n",
    "    thresh = threshold_otsu(img)\n",
    "    bin = img < thresh\n",
    "    skl = skeletonize(bin)\n",
    "    lbl = label(skl)\n",
    "#    lbl = label(bin)\n",
    "    cnt_lbl = np.bincount(lbl.reshape(-1))\n",
    "    max_lbl = np.argmax(cnt_lbl[1:]) + 1\n",
    "    lbl[lbl != max_lbl] = 0\n",
    "    lbl[lbl == max_lbl] = 1\n",
    "    r, c = lbl.shape\n",
    "    lbl = lbl[:, int(c / 2) :]\n",
    "    rgp = regionprops(lbl)\n",
    "    if len(rgp) == 0:\n",
    "        return 0\n",
    "    return rgp[0]['orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Сбор данных\n",
    "output_dirs_path = [input_dir_path + '_output' for input_dir_path in input_dirs_path]\n",
    "val = dict([])\n",
    "for output_dir_path in output_dirs_path:\n",
    "    val[output_dir_path] = list()\n",
    "    for num, filename in enumerate(iglob(output_dir_path + '/*.jpeg')):\n",
    "        img = imread(filename)\n",
    "        val[output_dir_path].append(get_val(img))\n",
    "#        if num == 20: break\n",
    "\n",
    "# Список в numpy-массив\n",
    "for k in val.keys():\n",
    "    val[k] = np.array(val[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07_output -0.0705918465367 0.084657964371\n",
      "02_output -0.392867745325 0.102428090527\n"
     ]
    }
   ],
   "source": [
    "res = dict()\n",
    "for k in val.keys():\n",
    "    print(k, val[k].mean(), val[k].std())\n",
    "    res[k] = val[k].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006719167669751653 seconds for one image\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "n = 0\n",
    "output_dirs_path = [input_dir_path + '_output' for input_dir_path in input_dirs_path]\n",
    "tic = time()\n",
    "for output_dir_path in output_dirs_path:\n",
    "    for filename in iglob(output_dir_path + '/*.jpeg'):\n",
    "        img = imread(filename)\n",
    "        res_v = get_val(img)\n",
    "        \n",
    "        dist_to_res = {k: v - res_v for k, v in res.items()}\n",
    "        res_k = min(dist_to_res, key = dist_to_res.get)\n",
    "        res_keys = list(res.keys())\n",
    "        if abs(res[res_keys[0]] - res_v) < abs(res[res_keys[1]] - res_v):\n",
    "            res_k = res_keys[0]\n",
    "        else:\n",
    "            res_k = res_keys[1]\n",
    "        n += 1\n",
    "        if res_k == output_dir_path:\n",
    "            s += 1\n",
    "toc = time()\n",
    "print('%s seconds for one image' % str((toc - tic) / n))\n",
    "ip_time = (toc - tic) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972318339100346\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %s' % str(s / n))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Try ML!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 768)\n",
      "(578,)\n"
     ]
    }
   ],
   "source": [
    "# Make data\n",
    "output_dirs_path = [input_dir_path + '_output' for input_dir_path in input_dirs_path]\n",
    "X = np.array([])\n",
    "for n_class, output_dir_path in enumerate(output_dirs_path):\n",
    "    for num, filename in enumerate(iglob(output_dir_path + '/*.jpeg')):\n",
    "        img = imread(filename)\n",
    "        new_size = (18, 50)\n",
    "        thresh = threshold_otsu(img)\n",
    "        bin = img < thresh\n",
    "        bin = resize(bin, new_size)\n",
    "        bin = bin[1:-1, 1:-1] * 255\n",
    "        bin = bin.astype('uint8')\n",
    "        thresh = threshold_otsu(bin)\n",
    "        bin = bin > thresh\n",
    "        \n",
    "        r, c = bin.shape\n",
    "        row = bin.reshape(1, r * c).squeeze()\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            X = np.array(row)\n",
    "            y = np.array(n_class)\n",
    "        else:\n",
    "            X = np.vstack((X, row))\n",
    "            y = np.hstack((y, n_class))\n",
    "            \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 768)\n",
      "(462,)\n",
      "(116, 768)\n",
      "(116,)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_part = 0.8\n",
    "idx = np.random.permutation(X.shape[0])\n",
    "\n",
    "train_idx = idx[: int(X.shape[0] * train_part)]\n",
    "test_idx = idx[int(X.shape[0] * train_part) :]\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now we try logreg!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=462, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,\n",
       "         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02,\n",
       "         1.00000e+03,   1.00000e+04,   1.00000e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search logreg\n",
    "\n",
    "kf = KFold(y_train.shape[0], n_folds = 5, shuffle = True)\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "clf = LogisticRegression(penalty = 'l2')\n",
    "gs = GridSearchCV(clf, grid, scoring = 'accuracy', cv = kf)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logreg\n",
    "clf = LogisticRegression(penalty = 'l2', **gs.best_params_)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test_set: 1.0\n",
      "Accuracy on all data: 0.998269896194\n",
      "1.2956816574622845e-05 seconds for one image\n"
     ]
    }
   ],
   "source": [
    "# Test logreg\n",
    "tic = time()\n",
    "print('Accuracy on test_set: %s' % str(clf.score(X_test, y_test)))\n",
    "toc = time()\n",
    "print('Accuracy on all data: %s' % str(clf.score(X, y)))\n",
    "print('%s seconds for one image' % str((toc - tic) / y_test.shape[0]))\n",
    "logreg_time = (toc - tic) / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now we try SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    6.7s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   26.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:   56.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:  1.5min\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:  2.2min\n",
      "[Parallel(n_jobs=1)]: Done 1600 out of 1600 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=462, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': array([  1.22070e-04,   2.44141e-04,   4.88281e-04,   9.76562e-04,\n",
       "         1.95312e-03,   3.90625e-03,   7.81250e-03,   1.56250e-02,\n",
       "         3.12500e-02,   6.25000e-02,   1.25000e-01,   2.50000e-01,\n",
       "         5.00000e-01,   1.00000e+00,   2.00000e+00,   4.00000e+00]), 'C': arra...,   5.12000e+02,   1.02400e+03,\n",
       "         2.04800e+03,   4.09600e+03,   8.19200e+03,   1.63840e+04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy',\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search SVM\n",
    "\n",
    "kf = KFold(y_train.shape[0], n_folds = 5, shuffle = True)\n",
    "grid = {'C': np.power(2.0, np.arange(-5, 15)), 'gamma': np.power(2.0, np.arange(-13, 3))}\n",
    "clf = svm.SVC(kernel = 'rbf')\n",
    "gs = GridSearchCV(clf, grid, scoring = 'accuracy', cv = kf, verbose = True)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=4.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.0078125, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM\n",
    "clf = svm.SVC(kernel = 'rbf', **gs.best_params_)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test_set: 1.0\n",
      "Accuracy on all data: 1.0\n",
      "8.977487169463059e-05 seconds for one image\n"
     ]
    }
   ],
   "source": [
    "# Test SVM\n",
    "tic = time()\n",
    "print('Accuracy on test_set: %s' % str(clf.score(X_test, y_test)))\n",
    "toc = time()\n",
    "print('Accuracy on all data: %s' % str(clf.score(X, y)))\n",
    "print('%s seconds for one image' % str((toc - tic) / y_test.shape[0]))\n",
    "svm_time = (toc - tic) / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm faster, than logreg: 0.14432564848096338x\n",
      "logreg faster, than image processing methods: 86.10595897809706x\n",
      "svm faster, than image processing methods: 12.42729836758909x\n"
     ]
    }
   ],
   "source": [
    "print('svm faster, than logreg: %sx' % str(logreg_time / svm_time))\n",
    "\n",
    "print('logreg faster, than image processing methods: %sx' % str(ip_time / logreg_time))\n",
    "print('svm faster, than image processing methods: %sx' % str(ip_time / svm_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
